{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pprint\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 20500 unique words in our dataset.\n"
     ]
    }
   ],
   "source": [
    "# Load and treat vocab\n",
    "with open('vocab.txt') as file:\n",
    "    vocab = file.readlines()\n",
    "    vocab = [line.rstrip() for line in vocab]\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "print('There are %d unique words in our dataset.' % vocab_size)\n",
    "\n",
    "# Hash table for words to indices and viceversa\n",
    "word_to_ix = { w:i for i,w in enumerate(vocab) }\n",
    "ix_to_word = { i:w for i,w in enumerate(vocab) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '00',\n",
       " '0000',\n",
       " '000000',\n",
       " '001',\n",
       " '004',\n",
       " '008',\n",
       " '01',\n",
       " '010',\n",
       " '01087',\n",
       " '011',\n",
       " '012',\n",
       " '016',\n",
       " '01745',\n",
       " '01918',\n",
       " '02',\n",
       " '020',\n",
       " '0201',\n",
       " '0208',\n",
       " '03',\n",
       " '032',\n",
       " '04',\n",
       " '040',\n",
       " '05',\n",
       " '052',\n",
       " '055',\n",
       " '056',\n",
       " '057',\n",
       " '06',\n",
       " '07',\n",
       " '0710',\n",
       " '0725',\n",
       " '08',\n",
       " '080',\n",
       " '081',\n",
       " '09',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '10000',\n",
       " '10006',\n",
       " '10007',\n",
       " '10029',\n",
       " '10079',\n",
       " '10081',\n",
       " '101',\n",
       " '1010',\n",
       " '102',\n",
       " '1024',\n",
       " '103',\n",
       " '1035',\n",
       " '104',\n",
       " '105',\n",
       " '106',\n",
       " '107',\n",
       " '108',\n",
       " '1082',\n",
       " '109',\n",
       " '11',\n",
       " '110',\n",
       " '1100',\n",
       " '111',\n",
       " '1110',\n",
       " '112',\n",
       " '1123',\n",
       " '113',\n",
       " '114',\n",
       " '115',\n",
       " '116',\n",
       " '117',\n",
       " '1179',\n",
       " '118',\n",
       " '119',\n",
       " '12',\n",
       " '120',\n",
       " '121',\n",
       " '122',\n",
       " '123',\n",
       " '124',\n",
       " '125',\n",
       " '1250',\n",
       " '1251',\n",
       " '1252',\n",
       " '126',\n",
       " '127',\n",
       " '128',\n",
       " '1282',\n",
       " '1284',\n",
       " '1285',\n",
       " '1288',\n",
       " '1291',\n",
       " '1296',\n",
       " '13',\n",
       " '1301',\n",
       " '1304',\n",
       " '1305',\n",
       " '1307',\n",
       " '131',\n",
       " '1311',\n",
       " '1314',\n",
       " '1317',\n",
       " '132',\n",
       " '1320',\n",
       " '133',\n",
       " '134',\n",
       " '137',\n",
       " '1370',\n",
       " '1377',\n",
       " '1394',\n",
       " '1395',\n",
       " '14',\n",
       " '141',\n",
       " '142',\n",
       " '1423',\n",
       " '14443',\n",
       " '145',\n",
       " '148',\n",
       " '1496',\n",
       " '15',\n",
       " '1500',\n",
       " '152',\n",
       " '1533',\n",
       " '1535',\n",
       " '156',\n",
       " '1578',\n",
       " '159',\n",
       " '1592',\n",
       " '16',\n",
       " '160',\n",
       " '162',\n",
       " '165',\n",
       " '1667',\n",
       " '1669',\n",
       " '1671',\n",
       " '1673',\n",
       " '1675',\n",
       " '168',\n",
       " '1680',\n",
       " '1682',\n",
       " '1687',\n",
       " '17',\n",
       " '171',\n",
       " '1713',\n",
       " '1716',\n",
       " '1732',\n",
       " '174',\n",
       " '175',\n",
       " '18',\n",
       " '180',\n",
       " '18030',\n",
       " '182',\n",
       " '1848',\n",
       " '185',\n",
       " '186',\n",
       " '1876',\n",
       " '19',\n",
       " '1918',\n",
       " '192',\n",
       " '1923',\n",
       " '1939',\n",
       " '1977',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '2005',\n",
       " '2009',\n",
       " '2012',\n",
       " '2022',\n",
       " '2047',\n",
       " '2048',\n",
       " '2062',\n",
       " '2068',\n",
       " '20860',\n",
       " '21',\n",
       " '210',\n",
       " '2104',\n",
       " '2112',\n",
       " '2113',\n",
       " '2120',\n",
       " '2121',\n",
       " '213',\n",
       " '219',\n",
       " '22',\n",
       " '220',\n",
       " '2208',\n",
       " '2231',\n",
       " '2232',\n",
       " '224',\n",
       " '2250',\n",
       " '23',\n",
       " '2315',\n",
       " '232',\n",
       " '234',\n",
       " '2345',\n",
       " '2388',\n",
       " '24',\n",
       " '2400',\n",
       " '2406',\n",
       " '2426',\n",
       " '2438',\n",
       " '2445',\n",
       " '2480',\n",
       " '2483',\n",
       " '25',\n",
       " '250',\n",
       " '2500',\n",
       " '251',\n",
       " '2523',\n",
       " '253',\n",
       " '255',\n",
       " '25519',\n",
       " '25538419688844',\n",
       " '256',\n",
       " '26',\n",
       " '263',\n",
       " '264',\n",
       " '27',\n",
       " '270',\n",
       " '2706',\n",
       " '2709',\n",
       " '28',\n",
       " '2800',\n",
       " '2821',\n",
       " '2822',\n",
       " '2834',\n",
       " '2864',\n",
       " '29',\n",
       " '30',\n",
       " '3000',\n",
       " '3068',\n",
       " '3072',\n",
       " '31',\n",
       " '3110',\n",
       " '3119',\n",
       " '3164',\n",
       " '32',\n",
       " '320',\n",
       " '3270',\n",
       " '33',\n",
       " '332',\n",
       " '3339',\n",
       " '3365',\n",
       " '34',\n",
       " '341',\n",
       " '3410',\n",
       " '3424',\n",
       " '345',\n",
       " '3455',\n",
       " '3484',\n",
       " '35',\n",
       " '350',\n",
       " '3526',\n",
       " '36',\n",
       " '360',\n",
       " '3657',\n",
       " '37',\n",
       " '38',\n",
       " '384',\n",
       " '386',\n",
       " '39',\n",
       " '390',\n",
       " '3950',\n",
       " '40',\n",
       " '400',\n",
       " '4000',\n",
       " '4014',\n",
       " '405',\n",
       " '406',\n",
       " '4096',\n",
       " '41',\n",
       " '416',\n",
       " '42',\n",
       " '420',\n",
       " '422',\n",
       " '425',\n",
       " '43',\n",
       " '437',\n",
       " '44',\n",
       " '443',\n",
       " '444',\n",
       " '45',\n",
       " '4510',\n",
       " '456',\n",
       " '46',\n",
       " '47',\n",
       " '4716',\n",
       " '477',\n",
       " '48',\n",
       " '485',\n",
       " '4897810065911',\n",
       " '49',\n",
       " '496',\n",
       " '50',\n",
       " '500',\n",
       " '501',\n",
       " '509',\n",
       " '51',\n",
       " '512',\n",
       " '52',\n",
       " '520',\n",
       " '521',\n",
       " '522022',\n",
       " '53',\n",
       " '530',\n",
       " '532',\n",
       " '5351',\n",
       " '54',\n",
       " '540',\n",
       " '5424',\n",
       " '55',\n",
       " '5511',\n",
       " '553',\n",
       " '5530',\n",
       " '5536',\n",
       " '555',\n",
       " '559',\n",
       " '56',\n",
       " '5600',\n",
       " '561',\n",
       " '562',\n",
       " '5634',\n",
       " '565',\n",
       " '568',\n",
       " '57',\n",
       " '573',\n",
       " '578',\n",
       " '58',\n",
       " '581',\n",
       " '584',\n",
       " '586',\n",
       " '588',\n",
       " '59',\n",
       " '591',\n",
       " '594',\n",
       " '596',\n",
       " '597',\n",
       " '60',\n",
       " '600',\n",
       " '601',\n",
       " '604',\n",
       " '607',\n",
       " '61',\n",
       " '610',\n",
       " '6100',\n",
       " '6103',\n",
       " '6105',\n",
       " '615',\n",
       " '61883',\n",
       " '62',\n",
       " '620',\n",
       " '623',\n",
       " '626',\n",
       " '627724',\n",
       " '63',\n",
       " '630',\n",
       " '633',\n",
       " '639',\n",
       " '64',\n",
       " '640',\n",
       " '6429',\n",
       " '6455',\n",
       " '65',\n",
       " '6502',\n",
       " '6513',\n",
       " '653052',\n",
       " '66',\n",
       " '6612',\n",
       " '67',\n",
       " '679509',\n",
       " '68',\n",
       " '6800',\n",
       " '686',\n",
       " '69',\n",
       " '70',\n",
       " '707',\n",
       " '71',\n",
       " '711',\n",
       " '72',\n",
       " '721',\n",
       " '722',\n",
       " '723',\n",
       " '73',\n",
       " '731',\n",
       " '732',\n",
       " '733',\n",
       " '737',\n",
       " '74',\n",
       " '75',\n",
       " '7507',\n",
       " '76',\n",
       " '77',\n",
       " '7727',\n",
       " '775',\n",
       " '7750',\n",
       " '7751',\n",
       " '78',\n",
       " '7816',\n",
       " '784',\n",
       " '787',\n",
       " '79',\n",
       " '80',\n",
       " '800',\n",
       " '802',\n",
       " '8021',\n",
       " '80211',\n",
       " '8023',\n",
       " '804',\n",
       " '8051',\n",
       " '80510',\n",
       " '805100',\n",
       " '805101',\n",
       " '805102',\n",
       " '805103',\n",
       " '805104',\n",
       " '805105',\n",
       " '805106',\n",
       " '805107',\n",
       " '805108',\n",
       " '805109',\n",
       " '80511',\n",
       " '805110',\n",
       " '805111',\n",
       " '805112',\n",
       " '805113',\n",
       " '805114',\n",
       " '805115',\n",
       " '805116',\n",
       " '805117',\n",
       " '805118',\n",
       " '805119',\n",
       " '80512',\n",
       " '805120',\n",
       " '805121',\n",
       " '805122',\n",
       " '805123',\n",
       " '805124',\n",
       " '805125',\n",
       " '805126',\n",
       " '805127',\n",
       " '805128',\n",
       " '805129',\n",
       " '80513',\n",
       " '805130',\n",
       " '805131',\n",
       " '805132',\n",
       " '805133',\n",
       " '805134',\n",
       " '805135',\n",
       " '805136',\n",
       " '805137',\n",
       " '805138',\n",
       " '805139',\n",
       " '80514',\n",
       " '805140',\n",
       " '805141',\n",
       " '805142',\n",
       " '805143',\n",
       " '805144',\n",
       " '805145',\n",
       " '805146',\n",
       " '805147',\n",
       " '805148',\n",
       " '805149',\n",
       " '80515',\n",
       " '805150',\n",
       " '805151',\n",
       " '805152',\n",
       " '805153',\n",
       " '805154',\n",
       " '805155',\n",
       " '805156',\n",
       " '805157',\n",
       " '805158',\n",
       " '805159',\n",
       " '80516',\n",
       " '805160',\n",
       " '805161',\n",
       " '805162',\n",
       " '805163',\n",
       " '805164',\n",
       " '805165',\n",
       " '805166',\n",
       " '805167',\n",
       " '805168',\n",
       " '805169',\n",
       " '80517',\n",
       " '805170',\n",
       " '805171',\n",
       " '805172',\n",
       " '805173',\n",
       " '805174',\n",
       " '805175',\n",
       " '805176',\n",
       " '805177',\n",
       " '805178',\n",
       " '805179',\n",
       " '80518',\n",
       " '805180',\n",
       " '805181',\n",
       " '805182',\n",
       " '805183',\n",
       " '805184',\n",
       " '805185',\n",
       " '805186',\n",
       " '805187',\n",
       " '805188',\n",
       " '805189',\n",
       " '80519',\n",
       " '805190',\n",
       " '805191',\n",
       " '805192',\n",
       " '805193',\n",
       " '805194',\n",
       " '805195',\n",
       " '805196',\n",
       " '805197',\n",
       " '805198',\n",
       " '805199',\n",
       " '81',\n",
       " '810',\n",
       " '815',\n",
       " '82',\n",
       " '820',\n",
       " '8212',\n",
       " '822',\n",
       " '823',\n",
       " '8237',\n",
       " '8252',\n",
       " '8253',\n",
       " '82802',\n",
       " '83',\n",
       " '830',\n",
       " '8300',\n",
       " '836',\n",
       " '83627',\n",
       " '83697',\n",
       " '83843',\n",
       " '83877',\n",
       " '83977',\n",
       " '84',\n",
       " '840',\n",
       " '85',\n",
       " '850',\n",
       " '8500',\n",
       " '852',\n",
       " '855',\n",
       " '857',\n",
       " '86',\n",
       " '860',\n",
       " '8601',\n",
       " '861',\n",
       " '8610',\n",
       " '862',\n",
       " '863',\n",
       " '864',\n",
       " '865',\n",
       " '866',\n",
       " '868',\n",
       " '869',\n",
       " '87',\n",
       " '8703',\n",
       " '8705',\n",
       " '8707',\n",
       " '8712',\n",
       " '8716',\n",
       " '8718',\n",
       " '8736',\n",
       " '874',\n",
       " '88',\n",
       " '8859',\n",
       " '89',\n",
       " '90',\n",
       " '900',\n",
       " '91',\n",
       " '9101',\n",
       " '915',\n",
       " '92',\n",
       " '923',\n",
       " '93',\n",
       " '931',\n",
       " '94',\n",
       " '945',\n",
       " '95',\n",
       " '958',\n",
       " '959',\n",
       " '96',\n",
       " '963',\n",
       " '965',\n",
       " '9660',\n",
       " '97',\n",
       " '975',\n",
       " '98',\n",
       " '981',\n",
       " '986',\n",
       " '99',\n",
       " '999',\n",
       " 'aa',\n",
       " 'aaa',\n",
       " 'aaaa',\n",
       " 'aac',\n",
       " 'aacdr',\n",
       " 'aacenc',\n",
       " 'aafs',\n",
       " 'aai',\n",
       " 'aal',\n",
       " 'aaxine',\n",
       " 'ab',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abar',\n",
       " 'abbr',\n",
       " 'abbrev',\n",
       " 'abbreviate',\n",
       " 'abbreviation',\n",
       " 'abbreviations',\n",
       " 'abbrevs',\n",
       " 'abc',\n",
       " 'abcd',\n",
       " 'abck',\n",
       " 'abe',\n",
       " 'abgr',\n",
       " 'abi',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'abit',\n",
       " 'abl',\n",
       " 'able',\n",
       " 'ablt',\n",
       " 'abm',\n",
       " 'abnormal',\n",
       " 'abon',\n",
       " 'abook',\n",
       " 'abor',\n",
       " 'abort',\n",
       " 'aborted',\n",
       " 'abortion',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abox',\n",
       " 'abr',\n",
       " 'abrt',\n",
       " 'abruptly',\n",
       " 'abs',\n",
       " 'absem',\n",
       " 'absent',\n",
       " 'abser',\n",
       " 'absolute',\n",
       " 'absorb',\n",
       " 'absorbing',\n",
       " 'abst',\n",
       " 'absthr',\n",
       " 'abstract',\n",
       " 'abstraction',\n",
       " 'absu',\n",
       " 'abut',\n",
       " 'abyss',\n",
       " 'ac',\n",
       " 'acar',\n",
       " 'acasecmp',\n",
       " 'acav',\n",
       " 'acc',\n",
       " 'acca',\n",
       " 'acccon',\n",
       " 'accel',\n",
       " 'accelerate',\n",
       " 'accelerator',\n",
       " 'accelerators',\n",
       " 'accelerometer',\n",
       " 'accels',\n",
       " 'accent',\n",
       " 'accenting',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'accepted',\n",
       " 'accepting',\n",
       " 'accepts',\n",
       " 'access',\n",
       " 'accesses',\n",
       " 'accessibility',\n",
       " 'accessible',\n",
       " 'accessing',\n",
       " 'accession',\n",
       " 'accessions',\n",
       " 'acci',\n",
       " 'accidental',\n",
       " 'acclst',\n",
       " 'accm',\n",
       " 'accommodate',\n",
       " 'according',\n",
       " 'account',\n",
       " 'accounting',\n",
       " 'accounts',\n",
       " 'acct',\n",
       " 'accu',\n",
       " 'accum',\n",
       " 'accumulate',\n",
       " 'accumulated',\n",
       " 'accumulator',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'ace',\n",
       " 'acep',\n",
       " 'acer',\n",
       " 'acfc',\n",
       " 'acg',\n",
       " 'ach',\n",
       " 'ache',\n",
       " 'acht',\n",
       " 'achtbc',\n",
       " 'achtbl',\n",
       " 'achtbs',\n",
       " 'achtcl',\n",
       " 'achtcs',\n",
       " 'achtds',\n",
       " 'achtil',\n",
       " 'achtl',\n",
       " 'achtlb',\n",
       " 'achtlc',\n",
       " 'achtld',\n",
       " 'achtli',\n",
       " 'achtll',\n",
       " 'achtlr',\n",
       " 'achtlu',\n",
       " 'achtlx',\n",
       " 'achtrl',\n",
       " 'achtrs',\n",
       " 'achtul',\n",
       " 'achtus',\n",
       " 'achtxl',\n",
       " 'achtxs',\n",
       " 'acim',\n",
       " 'ack',\n",
       " 'ackci',\n",
       " 'acknowledge',\n",
       " 'acknowledged',\n",
       " 'acl',\n",
       " 'aclose',\n",
       " 'aclri',\n",
       " 'aclrs',\n",
       " 'aclt',\n",
       " 'acm',\n",
       " 'acmd',\n",
       " 'acmod',\n",
       " 'acolyte',\n",
       " 'acpi',\n",
       " 'acpwr',\n",
       " 'acq',\n",
       " 'acquire',\n",
       " 'acquired',\n",
       " 'acquires',\n",
       " 'acquisition',\n",
       " 'acr',\n",
       " 'acre',\n",
       " 'acron',\n",
       " 'acrons',\n",
       " 'acs',\n",
       " 'acsc',\n",
       " 'acssdr',\n",
       " 'act',\n",
       " 'actf',\n",
       " 'actfrac',\n",
       " 'acti',\n",
       " 'action',\n",
       " 'actionable',\n",
       " 'actioner',\n",
       " 'actions',\n",
       " 'activate',\n",
       " 'activated',\n",
       " 'activates',\n",
       " 'activating',\n",
       " 'activation',\n",
       " 'activator',\n",
       " 'active',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actl',\n",
       " 'actor',\n",
       " 'actors',\n",
       " 'actrg',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actualize',\n",
       " 'actually',\n",
       " 'acw',\n",
       " 'ad',\n",
       " 'ada',\n",
       " 'adapt',\n",
       " 'adaptation',\n",
       " 'adapted',\n",
       " 'adapter',\n",
       " 'adapters',\n",
       " 'adaptive',\n",
       " 'adaptor',\n",
       " 'adaptors',\n",
       " 'adate',\n",
       " 'adc',\n",
       " 'adctest',\n",
       " 'add',\n",
       " 'adda',\n",
       " 'added',\n",
       " 'addend',\n",
       " 'addenda',\n",
       " 'addends',\n",
       " 'adder',\n",
       " 'addict',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'addr',\n",
       " 'address',\n",
       " 'addresses',\n",
       " 'addressing',\n",
       " 'adds',\n",
       " 'adef',\n",
       " 'adeh',\n",
       " 'adf',\n",
       " 'adios',\n",
       " 'adj',\n",
       " 'adjacent',\n",
       " 'adjday',\n",
       " 'adje',\n",
       " 'adjl',\n",
       " 'adjlon',\n",
       " 'adjmin',\n",
       " 'adjmon',\n",
       " 'adjoin',\n",
       " 'adjourn',\n",
       " 'adjpar',\n",
       " 'adjtitl',\n",
       " 'adjust',\n",
       " 'adjusted',\n",
       " 'adjuster',\n",
       " 'adjustment',\n",
       " 'adjustments',\n",
       " 'adjvol',\n",
       " 'adjwday',\n",
       " 'adkim',\n",
       " 'adm',\n",
       " 'admin',\n",
       " 'admit',\n",
       " 'admonish',\n",
       " 'admtek',\n",
       " 'adn',\n",
       " 'adns',\n",
       " 'ado',\n",
       " 'adobe',\n",
       " 'adoc',\n",
       " 'adopt',\n",
       " 'adoptions',\n",
       " 'adorn',\n",
       " 'adp',\n",
       " 'adpa',\n",
       " 'adpcm',\n",
       " 'adr',\n",
       " 'adrof',\n",
       " 'adrs',\n",
       " 'ads',\n",
       " 'adt',\n",
       " 'adu',\n",
       " 'adup',\n",
       " 'adus',\n",
       " 'adv',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advc',\n",
       " 'advert',\n",
       " 'advertise',\n",
       " 'advertisement',\n",
       " 'advertising',\n",
       " 'advise',\n",
       " 'advt',\n",
       " 'advws',\n",
       " 'adx',\n",
       " 'ae',\n",
       " 'aead',\n",
       " 'aend',\n",
       " 'aeol',\n",
       " 'aep',\n",
       " 'aer',\n",
       " 'aes',\n",
       " 'af',\n",
       " 'afc',\n",
       " 'afe',\n",
       " 'aff',\n",
       " 'affected',\n",
       " 'affine',\n",
       " 'affinities',\n",
       " 'affinity',\n",
       " 'affix',\n",
       " 'afford',\n",
       " 'afh',\n",
       " 'afield',\n",
       " 'afile',\n",
       " 'aflag',\n",
       " 'afm',\n",
       " 'afmt',\n",
       " 'afor',\n",
       " 'afp',\n",
       " 'afprun',\n",
       " 'afree',\n",
       " 'afs',\n",
       " 'afsk',\n",
       " 'aft',\n",
       " 'after',\n",
       " 'aftermath',\n",
       " 'ag',\n",
       " 'again',\n",
       " 'against',\n",
       " 'agar',\n",
       " 'agate',\n",
       " 'agc',\n",
       " 'agcep',\n",
       " 'agde',\n",
       " 'age',\n",
       " 'aged',\n",
       " 'ageing',\n",
       " 'agemap',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'aget',\n",
       " 'agf',\n",
       " 'agfst',\n",
       " 'agfstin',\n",
       " 'agg',\n",
       " 'agget',\n",
       " 'aggr',\n",
       " 'aggravate',\n",
       " 'aggregate',\n",
       " 'aggregation',\n",
       " 'aggregator',\n",
       " 'aglen',\n",
       " 'agn',\n",
       " 'agnx',\n",
       " 'agnxt',\n",
       " 'agnxtin',\n",
       " 'agre',\n",
       " 'agreement',\n",
       " 'ags',\n",
       " 'agset',\n",
       " 'agt',\n",
       " 'ague',\n",
       " 'agxb',\n",
       " 'agxbput',\n",
       " 'agxget',\n",
       " 'agxset',\n",
       " 'ah',\n",
       " 'ahci',\n",
       " 'ahead',\n",
       " 'ai',\n",
       " 'aible',\n",
       " 'aic',\n",
       " 'aid',\n",
       " 'aide',\n",
       " 'aif',\n",
       " 'aiff',\n",
       " 'ails',\n",
       " 'aim',\n",
       " 'ainit',\n",
       " 'air',\n",
       " 'airbrush',\n",
       " 'airplane',\n",
       " 'airport',\n",
       " 'airs',\n",
       " 'aisle',\n",
       " 'aix',\n",
       " 'aje',\n",
       " 'ajour',\n",
       " 'ajoute',\n",
       " 'ajp',\n",
       " 'ak',\n",
       " 'aka',\n",
       " 'akai',\n",
       " 'akey',\n",
       " 'akm',\n",
       " 'akmp',\n",
       " 'al',\n",
       " 'alac',\n",
       " 'alaf',\n",
       " 'alai',\n",
       " 'alarm',\n",
       " 'alarming',\n",
       " 'alarms',\n",
       " 'alaw',\n",
       " 'album',\n",
       " 'albums',\n",
       " 'alc',\n",
       " 'aldap',\n",
       " 'alemu',\n",
       " 'alert',\n",
       " 'alerts',\n",
       " 'alfred',\n",
       " 'alg',\n",
       " 'algebraic',\n",
       " 'algo',\n",
       " 'algor',\n",
       " 'algorithm',\n",
       " 'algorithms',\n",
       " 'algs',\n",
       " 'ali',\n",
       " 'alias',\n",
       " ...]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training set. \n",
    "dfs = pd.read_csv('ordered-labels-dataset-subsample.txt', delim_whitespace=True, index_col = 0, header = None, engine='python') #keep_default_na = False, Keep 'null' as valid value.\n",
    "\n",
    "# Build set with lists\n",
    "dfs['Words'] = dfs.dropna()[2].apply(lambda x: x.split('_'))\n",
    "# Build input for transformer: add space and end of line\n",
    "dfs['Names'] = dfs.dropna()['Words'].apply(lambda x: str(' ' + ' '.join(x) + ' \\n'))\n",
    "words_lists = list(dfs.loc[:,'Words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names = dfs['Names'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "32977             dpkg set prog name \\n\n",
       "32978              get int attribute \\n\n",
       "32979                  finalize test \\n\n",
       "32980                  run psm shell \\n\n",
       "32981      erlang backings tore grow \\n\n",
       "                      ...              \n",
       "329784                         sr dt \\n\n",
       "329785             chirp client link \\n\n",
       "329786           cgr preview forward \\n\n",
       "329787            game set color num \\n\n",
       "329788            mdns ec dns packet \\n\n",
       "Name: Names, Length: 296744, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names.to_csv('names.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    296744.000000\n",
       "mean          3.656994\n",
       "std           1.577809\n",
       "min           1.000000\n",
       "25%           3.000000\n",
       "50%           3.000000\n",
       "75%           5.000000\n",
       "max          17.000000\n",
       "Name: Name_length, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get stats regarding len of names\n",
    "dfs['Name_length'] = dfs['Words'].dropna().apply(lambda x: len(x))\n",
    "\n",
    "dfs['Name_length'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train and test. Build probability matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split in train and test set\n",
    "X_train, X_test = train_test_split(words_lists, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length of names: 17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  8,  0, ...,  1,  1,  0],\n",
       "       [ 0, 53,  0, ...,  0,  0,  1],\n",
       "       [ 0,  0,  1, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0, 68,  2, ...,  1,  1,  2]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of positions observed\n",
    "Tx = int(max(dfs['Name_length']))\n",
    "print('Maximum length of names:', Tx)\n",
    "\n",
    "# Matrix counting word appearances, row for position, columns for each word (among 20500 words)\n",
    "word_freq = np.zeros((Tx+1,vocab_size), dtype=np.int32)\n",
    "\n",
    "for i in range(Tx):\n",
    "    for word_list in X_train:\n",
    "        if isinstance(word_list,list) and len(word_list) > i:\n",
    "            word_freq[i,word_to_ix[word_list[i]] ] += 1\n",
    "\n",
    "# Last row: sum of appearances of each word\n",
    "for j in range(vocab_size):\n",
    "    word_freq[Tx,j] = sum(word_freq[:,j])\n",
    "            \n",
    "word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1561"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Words not appearing in training set:\n",
    "sum(word_freq[Tx,:] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq_normalized = word_freq[:Tx,:].astype(np.float32)\n",
    "\n",
    "# Normalize\n",
    "for j in range(vocab_size):\n",
    "    if sum(word_freq_normalized[:,j]) != 0:\n",
    "        word_freq_normalized[:,j] /= sum(word_freq_normalized[:Tx,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 20500)\n",
      "[[ 0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 53  0  0  9  0  0  3  0  0  0  2  0  0  0  1  0  3  0  0]\n",
      " [ 0  0  1  2  0  1  0  2  0  0  0  0  0  1  1  5  0  0  0  1]\n",
      " [ 0  4  1  1  0  0  1  4  2  0  1  0  0  0  0 16  1  0  1  1]\n",
      " [ 0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  1  0  0  0  0  0  0  0  1  0  0  0  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 68  2  3  9  1  1 10  4  0  1  2  0  1  1 23  1  3  1  3]]\n"
     ]
    }
   ],
   "source": [
    "# Summary of obtained matrices\n",
    "print(np.shape(word_freq))\n",
    "print(word_freq[:18,:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 20500)\n",
      "[[0.         0.11764706 0.         0.         0.        ]\n",
      " [0.         0.7794118  0.         0.         1.        ]\n",
      " [0.         0.         0.5        0.6666667  0.        ]\n",
      " [0.         0.05882353 0.5        0.33333334 0.        ]\n",
      " [0.         0.02941176 0.         0.         0.        ]\n",
      " [0.         0.01470588 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(word_freq_normalized))\n",
    "print(word_freq_normalized[:18,:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot showing names' length\n",
    "plt.plot([sum(word_freq[x,:]) for x in range(17)])\n",
    "plt.title('Names\\' lengths')\n",
    "plt.ylabel('Number of names')\n",
    "plt.xlabel('Number of words')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model (old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_probabilities(word_list):\n",
    "    permutations = list(itertools.permutations(word_list, len(word_list)))\n",
    "    print(permutations)\n",
    "    probs = np.zeros(len(permutations))\n",
    "    for ix, permutation in enumerate(permutations):\n",
    "        prob_tmp = 1\n",
    "        for i in range(len(permutation)):\n",
    "            prob_tmp *= word_freq_normalized[ i, word_to_ix[permutation[i]] ]\n",
    "            print(word_freq_normalized[ :, word_to_ix[permutation[i]] ])\n",
    "        probs[ix] = prob_tmp\n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('gdalget', 'gdu'), ('gdu', 'gdalget')]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.9655172  0.03448276 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.        ]\n",
      "[0.9655172  0.03448276 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.        ]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.03448276, 0.        ])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obtain_probabilities(['gdalget','gdu'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extend GPT2 vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful links for treating vocab:\n",
    "# https://discuss.huggingface.co/t/roberta-from-scratch-with-different-vocab-vs-fine-tuning/569\n",
    "# https://medium.com/@pierre_guillou/nlp-how-to-add-a-domain-specific-vocabulary-new-tokens-to-a-subword-tokenizer-already-trained-33ab15613a41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose DistilGPT2: GPT2 lighter version\n",
    "model_checkpoint = \"distilgpt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint) #vocab_file = 'vocab.txt' ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should I use the following vocab set ?\n",
    "# vocab_with_symbol = ['Ġ' + word for word in vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ĠCS': 9429,\n",
       " 'ĠThumbnails': 28924,\n",
       " 'ghan': 6064,\n",
       " 'porting': 26527,\n",
       " 'ĠLatter': 34437,\n",
       " 'ĠLore': 15639,\n",
       " 'ĠTerritories': 42354,\n",
       " 'Ġpertinent': 35268,\n",
       " 'Ġtechnology': 3037,\n",
       " 'Ġcrus': 25164,\n",
       " 'Ġcalcium': 19700,\n",
       " 'majority': 35839,\n",
       " 'ĠEval': 26439,\n",
       " 'Ġfaux': 36748,\n",
       " 'Ġagric': 8986,\n",
       " 'Ġcook': 4255,\n",
       " 'Ġdefinitive': 17347,\n",
       " 'Gallery': 29352,\n",
       " 'Enable': 36695,\n",
       " 'Ġantidepressant': 41897,\n",
       " 'ĠEuropeans': 20006,\n",
       " 'Ġrepent': 28787,\n",
       " 'Ġsweating': 38912,\n",
       " '################': 14468,\n",
       " 'Ġsmokers': 24109,\n",
       " 'Ġunamb': 42053,\n",
       " 'oooo': 13321,\n",
       " 'ĠErrors': 44225,\n",
       " 'ĠDresden': 46993,\n",
       " '================': 4770,\n",
       " 'Zip': 41729,\n",
       " 'Ġacc': 697,\n",
       " 'lights': 8091,\n",
       " 'Probably': 34784,\n",
       " 'ĠUn': 791,\n",
       " 'ĠObserver': 27058,\n",
       " 'ĠPreferences': 49780,\n",
       " 'psons': 31410,\n",
       " 'Ġunborn': 36172,\n",
       " 'Ġrain': 6290,\n",
       " 'Ġmotorcycles': 39404,\n",
       " 'ĠABV': 49993,\n",
       " 'akia': 21897,\n",
       " 'ĠPale': 21706,\n",
       " 'Ġarsen': 38924,\n",
       " 'obil': 25898,\n",
       " 'Ġcontradicts': 40081,\n",
       " 'Ġexemplary': 40690,\n",
       " 'Ġnon': 1729,\n",
       " 'Ġexcept': 2845,\n",
       " 'Ġhyper': 8718,\n",
       " 'Ġfucking': 9372,\n",
       " 'ble': 903,\n",
       " 'Consider': 19626,\n",
       " '384': 22842,\n",
       " 'Ġcommitted': 5364,\n",
       " 'Ġsends': 12800,\n",
       " 'Ġliqu': 14756,\n",
       " 'ĠSimple': 17427,\n",
       " 'ĠSchwar': 29726,\n",
       " 'Ġstereotype': 31240,\n",
       " '\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\': 34604,\n",
       " '885': 44230,\n",
       " 'Ġparanoid': 30285,\n",
       " 'Ġallowable': 49299,\n",
       " 'Ġivory': 32630,\n",
       " 'ĠEat': 27574,\n",
       " 'Ġappend': 24443,\n",
       " 'ĠBah': 13081,\n",
       " 'Ġsplits': 30778,\n",
       " 'ĠIre': 7181,\n",
       " 'wana': 49484,\n",
       " 'Ġpeople': 661,\n",
       " 'ĠOlympic': 11514,\n",
       " 'Ġrespiratory': 22949,\n",
       " 'aco': 10602,\n",
       " 'Ġphenomen': 7581,\n",
       " 'Ġdiplomatic': 13093,\n",
       " 'aky': 15492,\n",
       " 'Ġmodifications': 19008,\n",
       " 'Ġping': 29400,\n",
       " 'ĠZam': 38343,\n",
       " 'Ġrenewed': 16434,\n",
       " 'ĠClarkson': 40524,\n",
       " 'ĠActor': 27274,\n",
       " 'ĠSAY': 45687,\n",
       " 'Numbers': 49601,\n",
       " 'Ġweather': 6193,\n",
       " 'YOU': 36981,\n",
       " 'Ġpunished': 16851,\n",
       " 'Ġsuing': 28941,\n",
       " 'ĠHard': 6912,\n",
       " 'clamation': 20931,\n",
       " 'Ãº': 21356,\n",
       " 'Ġ329': 42141,\n",
       " 'normal': 11265,\n",
       " 'Ġsubstant': 5925,\n",
       " 'Ġintervention': 9572,\n",
       " 'Ġpresumed': 25751,\n",
       " 'PORT': 15490,\n",
       " 'iliated': 31705,\n",
       " 'consumer': 49827,\n",
       " 'Ġfort': 6285,\n",
       " 'Ġunconventional': 34014,\n",
       " 'addons': 39996,\n",
       " 'Ġcriterion': 34054,\n",
       " 'Ġcotton': 15985,\n",
       " 'Ġswimming': 14899,\n",
       " 'Ġillustrates': 21290,\n",
       " 'Ġelegance': 49198,\n",
       " 'Ġfue': 37911,\n",
       " 'ĠJugg': 39296,\n",
       " 'ĠPrevious': 21801,\n",
       " 'Ġfollowing': 1708,\n",
       " 'OPLE': 34354,\n",
       " 'Ġdrawer': 33451,\n",
       " 'Ġtariff': 36427,\n",
       " 'Atlantic': 41120,\n",
       " 'ĠTrave': 43662,\n",
       " 'ĠTeaching': 38094,\n",
       " 'Ġcontem': 7887,\n",
       " 'Ġquarry': 47780,\n",
       " '290': 24369,\n",
       " 'cy': 948,\n",
       " 'UR': 4261,\n",
       " 'ĠSpit': 48377,\n",
       " 'Ġchron': 16199,\n",
       " 'ĠWatson': 14959,\n",
       " 'Ġ520': 36141,\n",
       " 'Ġsolves': 39107,\n",
       " 'ĠWikiLeaks': 19766,\n",
       " 'cliffe': 33783,\n",
       " 'ĠMechanics': 47570,\n",
       " 'esson': 39670,\n",
       " 'Ok': 18690,\n",
       " 'Ġdebating': 31174,\n",
       " 'ĠMart': 3981,\n",
       " 'ĠVox': 28035,\n",
       " 'Ġunbiased': 46735,\n",
       " 'ĠO': 440,\n",
       " 'Ġpercentage': 5873,\n",
       " 'tl': 28781,\n",
       " 'ĠJoseph': 7212,\n",
       " 'ĠDebian': 26062,\n",
       " 'ĠPork': 44062,\n",
       " 'ĠComponent': 35100,\n",
       " 'Ġprofess': 2992,\n",
       " 'Ġbombard': 35285,\n",
       " 'Ġglamorous': 46185,\n",
       " 'ĠHemp': 50060,\n",
       " 'omic': 10179,\n",
       " 'ĠJord': 38317,\n",
       " 'Ġimmortal': 26156,\n",
       " 'Ġtypical': 7226,\n",
       " 'Ġ270': 20479,\n",
       " 'Ass': 8021,\n",
       " 'ĠStudio': 11733,\n",
       " 'Ġreplication': 30330,\n",
       " 'Ġclinical': 8668,\n",
       " 'bedroom': 36269,\n",
       " 'ĠInsight': 39917,\n",
       " 'Ġbuilds': 12188,\n",
       " 'Ġacqu': 4078,\n",
       " 'Ġstrongest': 12841,\n",
       " 'Ġcertain': 1728,\n",
       " 'aer': 25534,\n",
       " 'ctrl': 44755,\n",
       " 'Ġattacking': 9274,\n",
       " 'isition': 10027,\n",
       " 'Ġobtained': 6492,\n",
       " 'ĠJong': 17960,\n",
       " '--------------------': 19351,\n",
       " 'Ġassortment': 36168,\n",
       " 'essions': 6202,\n",
       " 'Ġrehears': 28779,\n",
       " 'oration': 6944,\n",
       " 'aquin': 48734,\n",
       " 'Ġrefuel': 47874,\n",
       " 'andan': 42509,\n",
       " 'iop': 14922,\n",
       " 'Ġempowerment': 39309,\n",
       " 'ĠRampage': 40244,\n",
       " 'Ġundesirable': 38117,\n",
       " 'ĠChinatown': 47043,\n",
       " 'ĠBearing': 28834,\n",
       " 'Ġdisappro': 22293,\n",
       " 'ĠKC': 25247,\n",
       " 'ĠBryant': 16754,\n",
       " 'Ġsaline': 47375,\n",
       " 'ĠVul': 25442,\n",
       " '571': 42875,\n",
       " 'Ġverified': 19000,\n",
       " 'Ġallegiance': 25696,\n",
       " 'Ġutilized': 21487,\n",
       " 'onnaissance': 31539,\n",
       " 'Ġrehearsal': 45795,\n",
       " 'Ġur': 2956,\n",
       " 'Ġinteg': 4132,\n",
       " 'ials': 8231,\n",
       " 'ĠAnime': 27812,\n",
       " 'ĠGemini': 35495,\n",
       " 'ĠBarrier': 32804,\n",
       " 'enfranch': 39827,\n",
       " 'perate': 30052,\n",
       " 'Ġadvertisers': 27835,\n",
       " 'Ġnudity': 42156,\n",
       " 'ĠDating': 43528,\n",
       " 'Ġanus': 47285,\n",
       " 'ĠSwordsman': 48318,\n",
       " 'Ġmoistur': 41189,\n",
       " 'third': 17089,\n",
       " 'Bernie': 33433,\n",
       " 'Ġtriggers': 20022,\n",
       " 'ĠPearl': 18482,\n",
       " 'Ġreward': 6721,\n",
       " 'ĠHank': 24386,\n",
       " 'ĠHive': 33235,\n",
       " 'Ġresearch': 2267,\n",
       " '030': 39101,\n",
       " 'Ġregistrations': 47997,\n",
       " 'Ġdepleted': 34069,\n",
       " 'ĠClosing': 47055,\n",
       " 'Ġ134': 22352,\n",
       " 'Ġpuppet': 30095,\n",
       " '2015': 4626,\n",
       " 'itures': 20686,\n",
       " 'Justin': 33229,\n",
       " 'ĠCait': 34118,\n",
       " 'Ġ490': 45601,\n",
       " 'Loading': 19031,\n",
       " 'Dig': 19511,\n",
       " 'agen': 11286,\n",
       " 'afety': 27925,\n",
       " 'Ġcompanions': 19429,\n",
       " 'Ġabsent': 13717,\n",
       " 'Ġ215': 22951,\n",
       " \"'?\": 30960,\n",
       " 'However': 4864,\n",
       " 'Ġcreepy': 23387,\n",
       " 'Ġmom': 1995,\n",
       " 'ĠPalm': 18358,\n",
       " 'ĠHercules': 32795,\n",
       " 'ĠPurch': 34459,\n",
       " 'ĠRollins': 47489,\n",
       " 'Ġ1945': 15761,\n",
       " 'Ġspecifying': 31577,\n",
       " 'Ġbelt': 10999,\n",
       " 'ĠEthernet': 31903,\n",
       " 'Ġ403': 38210,\n",
       " 'avin': 20637,\n",
       " 'Dual': 36248,\n",
       " 'Ġpredic': 41219,\n",
       " 'ĠPLoS': 49832,\n",
       " 'Ġeveryday': 10908,\n",
       " 'Ġscoreboard': 50198,\n",
       " 'Next': 10019,\n",
       " 'Ġdoubts': 17188,\n",
       " 'olit': 6212,\n",
       " 'ĠSto': 22025,\n",
       " 'ĠCenters': 22223,\n",
       " 'ĠBlocks': 35111,\n",
       " 'Ġexpecting': 12451,\n",
       " 'Ġpins': 20567,\n",
       " 'Ġexpenditures': 22895,\n",
       " 'Tracker': 35694,\n",
       " 'ĠDup': 37916,\n",
       " 'Ġfollowers': 10569,\n",
       " 'âķĲâķĲ': 31732,\n",
       " 'Yo': 38101,\n",
       " 'Ġleased': 40352,\n",
       " 'Ġtouch': 3638,\n",
       " 'ĠPed': 13457,\n",
       " 'Ġ273': 38549,\n",
       " 'Ġscaff': 41498,\n",
       " 'ĠTwitter': 3009,\n",
       " 'Ġadvantages': 13391,\n",
       " 'ĠSurve': 28095,\n",
       " 'Ġsound': 2128,\n",
       " 'Ġacknowled': 7333,\n",
       " 'cribed': 32968,\n",
       " 'bash': 41757,\n",
       " 'Ġlinebackers': 43081,\n",
       " 'TB': 22737,\n",
       " 'Ġformulate': 46418,\n",
       " 'ksh': 50133,\n",
       " 'ARK': 14175,\n",
       " 'ĠEntertainment': 11058,\n",
       " 'Ġwants': 3382,\n",
       " 'ĠCheese': 27601,\n",
       " 'ĠRod': 6882,\n",
       " 'OS': 2640,\n",
       " 'Ġhordes': 41872,\n",
       " 'ĠAds': 47442,\n",
       " 'wealth': 14298,\n",
       " 'Ġswayed': 47632,\n",
       " 'ĠMotorola': 31351,\n",
       " 'To': 2514,\n",
       " 'istrates': 37909,\n",
       " 'ĠRamsay': 47959,\n",
       " 'Ġmamm': 13418,\n",
       " 'Ġgrows': 13676,\n",
       " 'Ġinterpret': 6179,\n",
       " 'ĠWC': 28387,\n",
       " 'Got': 30074,\n",
       " 'actus': 34144,\n",
       " 'ĠMusic': 7849,\n",
       " 'Ġgotten': 7891,\n",
       " 'Ġstomach': 11384,\n",
       " 'Ġmodule': 8265,\n",
       " 'ĠBC': 11843,\n",
       " 'PLE': 16437,\n",
       " 'apesh': 25490,\n",
       " 'orrect': 47315,\n",
       " 'eks': 2573,\n",
       " 'Ġhistories': 25985,\n",
       " 'ĠSlip': 49988,\n",
       " 'Ġevent': 1785,\n",
       " 'isms': 6583,\n",
       " 'ĠCool': 15226,\n",
       " 'ĠFactory': 19239,\n",
       " 'elaide': 25078,\n",
       " 'ĠWatch': 6305,\n",
       " 'Ġalarmed': 32064,\n",
       " 'crim': 50086,\n",
       " 'Ġdonor': 17052,\n",
       " 'Ġhas': 468,\n",
       " 'Ġtirelessly': 47905,\n",
       " 'Ġstairs': 16046,\n",
       " 'Ġeternal': 15851,\n",
       " 'Ġcatalog': 18388,\n",
       " 'ucci': 27501,\n",
       " 'ĠWork': 5521,\n",
       " 'ĠADD': 27841,\n",
       " 'uted': 7241,\n",
       " 'ĠDestiny': 17886,\n",
       " 'weapons': 33999,\n",
       " 'ĠRecreation': 34285,\n",
       " 'Ġdenotes': 43397,\n",
       " 'Ġspir': 9158,\n",
       " 'Ġ97': 10111,\n",
       " 'ĠJavaScript': 11933,\n",
       " 'Ġimposing': 20814,\n",
       " 'Ġstrides': 35002,\n",
       " 'Ġdeclines': 24459,\n",
       " 'ĠFaust': 47411,\n",
       " 'Ġpunt': 35363,\n",
       " 'Ġslot': 10852,\n",
       " 'Stud': 13007,\n",
       " 'Ġ204': 26956,\n",
       " 'Ġdisruptive': 28094,\n",
       " 'Images': 29398,\n",
       " 'ague': 2064,\n",
       " 'ĠMines': 33466,\n",
       " 'Ġunsatisf': 39264,\n",
       " 'Ġpublicized': 42732,\n",
       " 'engeance': 21364,\n",
       " 'Ġphilanthrop': 28150,\n",
       " 'ĠSTE': 24483,\n",
       " 'rak': 17716,\n",
       " 'Ġ02': 7816,\n",
       " '](': 16151,\n",
       " 'AK': 10206,\n",
       " 'iker': 18320,\n",
       " 'ighton': 42993,\n",
       " 'ĠHY': 43624,\n",
       " 'Ak': 33901,\n",
       " 'ĠBadge': 44308,\n",
       " 'redited': 19465,\n",
       " 'Ġsorcery': 47815,\n",
       " 'Ġspeak': 2740,\n",
       " 'Ġmisunder': 16782,\n",
       " 'Ġtrajectory': 22942,\n",
       " 'esm': 45798,\n",
       " 'ĠDMV': 49887,\n",
       " ',)': 35751,\n",
       " 'outheast': 14474,\n",
       " '080': 33057,\n",
       " 'Ġfilming': 17691,\n",
       " 'Ġencrypt': 34117,\n",
       " 'ir': 343,\n",
       " 'elli': 23225,\n",
       " 'ĠHero': 8757,\n",
       " 'uddenly': 18865,\n",
       " 'Ġpercentile': 37894,\n",
       " 'Ġfleeting': 42738,\n",
       " 'ĠTelecom': 44021,\n",
       " 'Ġcan': 460,\n",
       " 'Ġthorough': 9321,\n",
       " 'icide': 5285,\n",
       " 'Ġskillet': 41306,\n",
       " 'merce': 11647,\n",
       " 'Ġ198': 2757,\n",
       " 'layout': 39786,\n",
       " 'ĠPackage': 15717,\n",
       " 'Ban': 30457,\n",
       " 'abling': 11716,\n",
       " 'ĠRender': 46722,\n",
       " 'existent': 32786,\n",
       " 'iped': 46647,\n",
       " 'owl': 4883,\n",
       " 'met': 4164,\n",
       " 'oves': 5241,\n",
       " 'Ġâī': 15139,\n",
       " 'ceptive': 25867,\n",
       " 'ĠREST': 30617,\n",
       " 'ĠAppropriations': 37552,\n",
       " 'Ġrapist': 38007,\n",
       " 'ĠHuntington': 40644,\n",
       " 'Ġafterward': 20875,\n",
       " 'ĠLLP': 43245,\n",
       " 'Ġdow': 47276,\n",
       " 'Ġ169': 27191,\n",
       " 'puted': 17128,\n",
       " 'ĠMem': 4942,\n",
       " 'Ġprogresses': 33226,\n",
       " 'Ġmu': 38779,\n",
       " 'onents': 3906,\n",
       " 'on': 261,\n",
       " 'Ġspoon': 24556,\n",
       " 'IX': 10426,\n",
       " 'ĠConsortium': 42727,\n",
       " 'ukong': 46654,\n",
       " 'Ġ+++': 49954,\n",
       " 'Ġshader': 33030,\n",
       " 'Ġregulates': 39474,\n",
       " 'Ġ1981': 14745,\n",
       " 'Ġmathematical': 18069,\n",
       " 'Type': 6030,\n",
       " 'ĠItem': 9097,\n",
       " 'ĠLiberty': 14734,\n",
       " 'xxxxxxxx': 24223,\n",
       " 'Ġpreliminary': 15223,\n",
       " 'ears': 4127,\n",
       " 'Ġ[[': 16410,\n",
       " 'Ġhighways': 27239,\n",
       " 'Ġlot': 1256,\n",
       " 'Ġwhis': 12563,\n",
       " 'notations': 30078,\n",
       " 'aths': 33148,\n",
       " 'Ġmorals': 35472,\n",
       " 'oxic': 18047,\n",
       " 'ĠBerk': 35595,\n",
       " 'Ġreconnaissance': 39471,\n",
       " 'awan': 43004,\n",
       " 'Ġ66': 7930,\n",
       " 'ĠArcane': 26475,\n",
       " 'ijah': 32778,\n",
       " 'yout': 32015,\n",
       " 'gements': 43547,\n",
       " 'ĠDodd': 32145,\n",
       " 'ctl': 34168,\n",
       " 'ĠChandra': 46295,\n",
       " 'Ġtell': 1560,\n",
       " 'articles': 26845,\n",
       " '800': 7410,\n",
       " 'asers': 19865,\n",
       " 'Ġoccupancy': 42498,\n",
       " 'Ġbay': 15489,\n",
       " 'Ġteach': 4545,\n",
       " 'Ġeff': 914,\n",
       " 'Ġdetection': 13326,\n",
       " 'eval': 18206,\n",
       " 'Ultimate': 47892,\n",
       " 'ĠPlenty': 43257,\n",
       " 'udder': 41686,\n",
       " 'Ġaccomplishments': 26516,\n",
       " 'ual': 723,\n",
       " 'ĠRim': 29542,\n",
       " '+)': 28988,\n",
       " 'NW': 27605,\n",
       " 'though': 2016,\n",
       " 'Id': 7390,\n",
       " 'ĠImprovements': 45097,\n",
       " 'Smith': 17919,\n",
       " 'KA': 25123,\n",
       " 'ĠSkywalker': 29715,\n",
       " '513': 48645,\n",
       " 'Ġtransition': 6801,\n",
       " 'Rain': 31443,\n",
       " 'ĠDOC': 37760,\n",
       " 'ilian': 35824,\n",
       " '258': 25600,\n",
       " 'Ġapplicable': 9723,\n",
       " 'ĠNay': 38808,\n",
       " 'Ġmer': 4017,\n",
       " 'Ġpostal': 30793,\n",
       " '\"...': 26214,\n",
       " 'binary': 39491,\n",
       " 'ogi': 44381,\n",
       " 'ĠCubs': 21562,\n",
       " 'Ġdoping': 42631,\n",
       " 'Ġpure': 5899,\n",
       " 'Ġspeed': 2866,\n",
       " 'women': 25878,\n",
       " 'Ġappreciation': 19163,\n",
       " 'Andy': 35314,\n",
       " 'ĠPeru': 25768,\n",
       " 'Ġmarg': 6145,\n",
       " 'ĠTh': 536,\n",
       " 'ĠInternational': 4037,\n",
       " 'ĠPerform': 35006,\n",
       " 'Ġ_': 4808,\n",
       " 'letal': 47293,\n",
       " 'Ġjustification': 17734,\n",
       " 'imedia': 20626,\n",
       " 'ĠTimberwolves': 48983,\n",
       " 'Eng': 7936,\n",
       " 'ĠAssoci': 3928,\n",
       " 'ĠFinished': 42931,\n",
       " 'Ġdetainee': 49436,\n",
       " 'Ġrepetition': 29693,\n",
       " 'ĠWitch': 14522,\n",
       " 'Ġpriest': 11503,\n",
       " 'ĠFA': 9677,\n",
       " 'Ġdaunting': 30496,\n",
       " 'ĠYanuk': 37068,\n",
       " 'Ġate': 15063,\n",
       " 'Ġ((': 14808,\n",
       " 'Ġstate': 1181,\n",
       " 'Ġdrops': 10532,\n",
       " 'ĠMLB': 18532,\n",
       " 'ĠTavern': 32693,\n",
       " 'ĠRW': 33212,\n",
       " 'ĠHousehold': 37306,\n",
       " 'Ġrapes': 37459,\n",
       " 'ĠRIP': 44967,\n",
       " 'Ġcaveats': 47155,\n",
       " 'Ġempirical': 21594,\n",
       " 'ĠSituation': 49465,\n",
       " 'ĠLiang': 43322,\n",
       " 'api': 15042,\n",
       " 'Eye': 24876,\n",
       " 'ĠMont': 5575,\n",
       " 'Ġlod': 19527,\n",
       " 'Ġhealthcare': 11409,\n",
       " 'Ġembarrassing': 18997,\n",
       " 'hesis': 8497,\n",
       " 'mbol': 23650,\n",
       " 'Ġcomprehensive': 9815,\n",
       " 'Ġsheets': 15747,\n",
       " 'Ġrelates': 18436,\n",
       " 'ĠCHO': 49143,\n",
       " 'Ġnewcomers': 29661,\n",
       " 'Loader': 17401,\n",
       " 'ravings': 42335,\n",
       " 'Solution': 46344,\n",
       " 'ĠRBI': 20948,\n",
       " 'Ġgrassroots': 23783,\n",
       " 'Ġsolder': 42809,\n",
       " 'ĠWhitney': 34701,\n",
       " 'ĠMcN': 22586,\n",
       " 'ISC': 37719,\n",
       " 'azon': 5168,\n",
       " 'otechnology': 31201,\n",
       " 'Ġbask': 39353,\n",
       " 'ĠCure': 36947,\n",
       " 'Ġcompound': 13061,\n",
       " 'Ġappearances': 11057,\n",
       " 'Ġalter': 8343,\n",
       " 'ĠBelief': 49728,\n",
       " 'Ġmanufacturing': 9138,\n",
       " 'cedes': 19285,\n",
       " 'ĠChest': 25544,\n",
       " '313': 25838,\n",
       " 'Ġsitting': 5586,\n",
       " 'reviewed': 32974,\n",
       " \"('\": 10786,\n",
       " '\":\"\",\"': 34713,\n",
       " 'Ġviolation': 8747,\n",
       " 'Ġhangar': 44338,\n",
       " 'ĠVerify': 49899,\n",
       " '860': 45039,\n",
       " 'rand': 25192,\n",
       " 'Ġwriting': 3597,\n",
       " 'ĠBritain': 5491,\n",
       " 'ĠNHS': 18183,\n",
       " 'ItemImage': 25502,\n",
       " 'ĠNoah': 18394,\n",
       " 'Ġpuzzling': 42695,\n",
       " 'FIN': 20032,\n",
       " 'Ġund': 3318,\n",
       " 'wrong': 36460,\n",
       " 'up': 929,\n",
       " 'ju': 14396,\n",
       " 'IDES': 42538,\n",
       " 'Ġundergo': 17777,\n",
       " 'Ġpattern': 3912,\n",
       " 'Ġpromoting': 11560,\n",
       " 'gs': 14542,\n",
       " 'bernatorial': 43660,\n",
       " 'Ġlandsl': 29433,\n",
       " 'ĠOttawa': 14074,\n",
       " 'ĠScouts': 30456,\n",
       " 'ĠUganda': 30872,\n",
       " 'Ġbore': 18631,\n",
       " 'ĠCases': 35536,\n",
       " 'Were': 35653,\n",
       " 'Ġ171': 28369,\n",
       " 'Ġcrocod': 37565,\n",
       " '755': 38172,\n",
       " 'ardy': 39124,\n",
       " 'Detroit': 40404,\n",
       " '060': 41322,\n",
       " 'ĠGrammy': 42235,\n",
       " 'ĠTrident': 47907,\n",
       " 'ĠJem': 48199,\n",
       " 'Links': 31815,\n",
       " 'Ġdefunct': 49119,\n",
       " '538': 49561,\n",
       " 'ĠDream': 7610,\n",
       " 'Ġflips': 45971,\n",
       " 'ĠInput': 23412,\n",
       " 'Position': 26545,\n",
       " 'ouston': 6526,\n",
       " 'Ġdislike': 23109,\n",
       " 'Ġpedal': 26667,\n",
       " 'à¤': 11976,\n",
       " 'rodu': 2076,\n",
       " 'Ġsunlight': 19606,\n",
       " 'Ġpassports': 33052,\n",
       " 'Ġcertificate': 10703,\n",
       " 'Think': 22073,\n",
       " 'ĠAstro': 35167,\n",
       " 'Ġmsec': 43242,\n",
       " 'å¥³': 42637,\n",
       " 'ĠVarg': 44684,\n",
       " 'Ġitch': 49700,\n",
       " 'Ġsuffers': 21046,\n",
       " 'anuts': 37555,\n",
       " '1981': 35411,\n",
       " 'ĠRepresentative': 19920,\n",
       " 'between': 23395,\n",
       " 'Ġanecdotal': 41666,\n",
       " 'CON': 10943,\n",
       " 'ĠBugs': 44991,\n",
       " 'olia': 22703,\n",
       " 'ettings': 12374,\n",
       " 'olute': 3552,\n",
       " 'Ġsy': 827,\n",
       " 'using': 3500,\n",
       " '.-': 7874,\n",
       " 'Ġposter': 11968,\n",
       " 'science': 16801,\n",
       " 'ĠLS': 30948,\n",
       " 'Mic': 25437,\n",
       " 'jured': 38608,\n",
       " 'Ġactivated': 13906,\n",
       " 'Ġnavy': 23956,\n",
       " 'Ġdepend': 4745,\n",
       " 'Ġpillow': 28774,\n",
       " 'ĠRobo': 39702,\n",
       " 'Ġpadded': 44582,\n",
       " 'ash': 1077,\n",
       " 'Ġnont': 45930,\n",
       " 'Adds': 46245,\n",
       " 'ĠSexy': 49131,\n",
       " '733': 49995,\n",
       " 'Ġbehavi': 6598,\n",
       " 'fold': 11379,\n",
       " 'cfg': 37581,\n",
       " 'Ġ1993': 9656,\n",
       " 'ĠLudwig': 44476,\n",
       " 'rius': 48969,\n",
       " 'Ġneural': 17019,\n",
       " 'Ġorphans': 50213,\n",
       " 'Ġgazed': 50255,\n",
       " 'Ġ433': 47407,\n",
       " 'Ġ&': 1222,\n",
       " 'bar': 5657,\n",
       " 'ĠSteal': 47242,\n",
       " 'Ġpartial': 13027,\n",
       " 'ĠPower': 4333,\n",
       " 'Chief': 23675,\n",
       " 'Ġunrecogn': 43483,\n",
       " 'Ġexpenses': 9307,\n",
       " 'Ġseeming': 31792,\n",
       " 'Ġworsh': 26511,\n",
       " 'Ġpenetrate': 28302,\n",
       " 'ĠThur': 36975,\n",
       " 'ortmund': 34876,\n",
       " 'counter': 24588,\n",
       " 'Ġattrition': 48981,\n",
       " 'ĠAcad': 7116,\n",
       " 'ĠNever': 7236,\n",
       " 'ĠMercury': 21673,\n",
       " 'bec': 9423,\n",
       " 'acies': 13433,\n",
       " 'lists': 20713,\n",
       " 'ĠAin': 31899,\n",
       " 'moderate': 47189,\n",
       " 'Ġexploitation': 17238,\n",
       " 'Ġawaited': 39576,\n",
       " 'owers': 3618,\n",
       " 'ĠNewark': 30970,\n",
       " 'Ġdemonstr': 4110,\n",
       " 'quality': 13237,\n",
       " 'ĠPatriots': 13104,\n",
       " 'ĠAuthority': 11416,\n",
       " 'paying': 32629,\n",
       " 'Ġmasturb': 22938,\n",
       " 'ĠOf': 3226,\n",
       " 'ĠGeorgetown': 31393,\n",
       " 'outh': 1536,\n",
       " 'rieving': 37418,\n",
       " 'ĠRagnarok': 40451,\n",
       " 'ĠRacial': 42318,\n",
       " 'Ġlearned': 4499,\n",
       " '\\\\/\\\\/': 45422,\n",
       " 'tics': 14094,\n",
       " 'ĠLuke': 11336,\n",
       " 'Ġrecord': 1700,\n",
       " 'ogly': 34619,\n",
       " 'Ġtumble': 47978,\n",
       " 'ac': 330,\n",
       " 'ATIONS': 18421,\n",
       " 'Ġbeverages': 24173,\n",
       " 'Ġformulas': 32126,\n",
       " 'Ġtcp': 48265,\n",
       " 'ĠConcern': 32265,\n",
       " 'Ġabbrevi': 37640,\n",
       " '578': 38907,\n",
       " 'Ġanyways': 32845,\n",
       " 'ettel': 47417,\n",
       " 'Ġcoated': 30267,\n",
       " 'Ġreiter': 19291,\n",
       " 'ITAL': 40579,\n",
       " 'ĠChick': 31939,\n",
       " 'Ġretreat': 13703,\n",
       " 'ĠLone': 23405,\n",
       " 'volent': 29078,\n",
       " 'ĠESC': 40251,\n",
       " 'NOT': 11929,\n",
       " 'Edward': 43982,\n",
       " 'Ġpillars': 30485,\n",
       " './': 19571,\n",
       " 'Ġuncertain': 8627,\n",
       " 'Ġposture': 24521,\n",
       " 'ĠAb': 2275,\n",
       " 'Clinton': 16549,\n",
       " 'ĠSl': 3454,\n",
       " 'ĠInterest': 12033,\n",
       " 'dial': 38969,\n",
       " 'Ġgrips': 31323,\n",
       " 'Monday': 23810,\n",
       " 'Ġintr': 9913,\n",
       " 'Ġimporting': 33332,\n",
       " 'Ġtown': 3240,\n",
       " 'hyp': 36362,\n",
       " 'Ġbro': 1379,\n",
       " 'Ġcul': 10845,\n",
       " 'Ġguideline': 40888,\n",
       " 'ovich': 18198,\n",
       " 'ĠMicha': 38844,\n",
       " 'Ġsnag': 48456,\n",
       " 'ĠKhe': 48888,\n",
       " 'Ġnurse': 15849,\n",
       " 'acan': 50195,\n",
       " 'Ġsuccessor': 17270,\n",
       " ']]': 11907,\n",
       " 'usalem': 10555,\n",
       " 'Ġshape': 5485,\n",
       " 'Ġambassador': 14791,\n",
       " 'ĠLean': 45661,\n",
       " 'Ġlab': 2248,\n",
       " 'animal': 41607,\n",
       " 'azz': 8101,\n",
       " 'Ġplayed': 2826,\n",
       " 'Lear': 14961,\n",
       " 'ĠJab': 24404,\n",
       " 'ĠLists': 44968,\n",
       " 'Pierre': 36910,\n",
       " 'scar': 13034,\n",
       " 'Defense': 27300,\n",
       " 'Ġeuphem': 48732,\n",
       " 'Ġnotable': 12411,\n",
       " 'Ġdeal': 1730,\n",
       " 'Ġhog': 40476,\n",
       " 'Ġdimensions': 15225,\n",
       " 'Ġagile': 36710,\n",
       " 'Ġrepl': 2186,\n",
       " 'Ġper': 583,\n",
       " 'ĠJing': 42279,\n",
       " 'Ġobserv': 3799,\n",
       " 'invest': 24859,\n",
       " 'Ġperfect': 2818,\n",
       " 'lez': 36858,\n",
       " 'Ġlicences': 45475,\n",
       " '275': 23195,\n",
       " 'baum': 24738,\n",
       " '?),': 33924,\n",
       " 'Ġcontainment': 37149,\n",
       " 'andr': 46273,\n",
       " 'Ġinterviewed': 12299,\n",
       " 'pered': 13653,\n",
       " 'ĠCogn': 26543,\n",
       " 'Footnote': 33795,\n",
       " 'ss': 824,\n",
       " 'Ġsoften': 39536,\n",
       " 'Ġicons': 17149,\n",
       " 'needed': 27938,\n",
       " 'Ġcounted': 14789,\n",
       " 'Ġrepercussions': 34056,\n",
       " '7601': 42752,\n",
       " 'ĠColumn': 29201,\n",
       " 'Ġprotestors': 36915,\n",
       " 'ĠMAN': 17254,\n",
       " 'Ġaggregation': 46500,\n",
       " 'Ġenraged': 37530,\n",
       " 'Library': 23377,\n",
       " 'ĠRugby': 26244,\n",
       " 'itivity': 11365,\n",
       " 'Ġverbally': 38119,\n",
       " 'Ġè£ıè¦ļéĨĴ': 25992,\n",
       " 'Textures': 39860,\n",
       " 'roximately': 24378,\n",
       " 'Ġcondem': 8346,\n",
       " 'maps': 31803,\n",
       " 'Ġredd': 14688,\n",
       " 'collect': 33327,\n",
       " 'Ġblasting': 36998,\n",
       " 'Ġincapac': 38533,\n",
       " 'Ġintermediary': 45193,\n",
       " 'ĠPhil': 4543,\n",
       " 'lations': 49905,\n",
       " 'Ġhis': 465,\n",
       " 'Ġexpress': 4911,\n",
       " 'Ġarguments': 7159,\n",
       " 'Ġboat': 8848,\n",
       " 'Class': 9487,\n",
       " 'Ġ1983': 13540,\n",
       " 'Ġrecorded': 6264,\n",
       " 'rat': 10366,\n",
       " 'ĠVolt': 22702,\n",
       " 'ĠHogwarts': 30922,\n",
       " 'Ġtrenches': 40068,\n",
       " 'Ġvowel': 48617,\n",
       " 'iencies': 22139,\n",
       " 'Ġscreenshots': 23322,\n",
       " 'ĠTables': 33220,\n",
       " '162': 25061,\n",
       " 'Ġgarments': 36097,\n",
       " 'util': 22602,\n",
       " 'acia': 47431,\n",
       " 'ODUCT': 28644,\n",
       " 'ĠThro': 47854,\n",
       " 'Ġclassy': 48486,\n",
       " 'ĠBrett': 18726,\n",
       " 'ri': 380,\n",
       " 'reader': 46862,\n",
       " 'ĠShine': 41249,\n",
       " 'arts': 5889,\n",
       " 'arantine': 37996,\n",
       " 'Ġinstinct': 13311,\n",
       " 'Ġins': 1035,\n",
       " 'ĠCosta': 18133,\n",
       " 'Ġslap': 23905,\n",
       " 'hetto': 35619,\n",
       " 'Ġselectively': 39119,\n",
       " '820': 41739,\n",
       " 'CAN': 44565,\n",
       " 'Earn': 49725,\n",
       " 'Ġinterns': 47266,\n",
       " 'Ġgrocery': 16918,\n",
       " 'cence': 43696,\n",
       " 'cano': 35490,\n",
       " 'RIPT': 46023,\n",
       " 'Ge': 10082,\n",
       " 'ĠSoviets': 31062,\n",
       " 'Ġripping': 34759,\n",
       " 'Gro': 42921,\n",
       " 'Ġdeliberate': 18988,\n",
       " 'ĠMayhem': 35450,\n",
       " 'checking': 41004,\n",
       " 'Ġembarked': 36385,\n",
       " 'ĠIPO': 41805,\n",
       " 'ĠBite': 44540,\n",
       " 'issa': 13808,\n",
       " 'ĠReach': 25146,\n",
       " 'Ġquirky': 37276,\n",
       " 'Wow': 22017,\n",
       " 'Mo': 16632,\n",
       " 'gz': 34586,\n",
       " 'Ġ248': 32996,\n",
       " 'BER': 13246,\n",
       " 'brand': 17938,\n",
       " 'Ġhanding': 22786,\n",
       " 'Ġgroundwork': 40641,\n",
       " 'CAR': 20034,\n",
       " 'Ġlisted': 5610,\n",
       " 'ĠEastern': 8345,\n",
       " 'ĠYar': 45184,\n",
       " 'Employ': 29733,\n",
       " 'Hal': 40202,\n",
       " 'Ġcharacteristic': 16704,\n",
       " 'ras': 8847,\n",
       " 'ĠiCloud': 42076,\n",
       " 'ĠSr': 21714,\n",
       " 'Ġdefinitely': 4753,\n",
       " 'Ġunauthorized': 22959,\n",
       " 'ĠTranslation': 33322,\n",
       " 'Ġmodify': 13096,\n",
       " 'Ġrelationship': 2776,\n",
       " 'Project': 16775,\n",
       " 'Ġsprang': 43908,\n",
       " 'ians': 1547,\n",
       " 'Ġpicnic': 35715,\n",
       " 'were': 22474,\n",
       " 'Brian': 24761,\n",
       " 'Tro': 44095,\n",
       " 'ĠTwitch': 23835,\n",
       " '753': 44550,\n",
       " 'ĠRebecca': 23489,\n",
       " 'Sounds': 40825,\n",
       " 'haus': 30404,\n",
       " 'Bob': 18861,\n",
       " 'pad': 15636,\n",
       " 'ique': 2350,\n",
       " 'tick': 42298,\n",
       " 'Ġdiscussion': 5114,\n",
       " 'Texas': 21607,\n",
       " 'krit': 44531,\n",
       " 'Ġauto': 8295,\n",
       " 'ĠKenny': 22102,\n",
       " 'axter': 40864,\n",
       " 'ĠOsaka': 42429,\n",
       " 'Ġpile': 14540,\n",
       " 'Ġkick': 4829,\n",
       " 'ĠGT': 7963,\n",
       " 'Ġversion': 2196,\n",
       " 'okemon': 12717,\n",
       " 'mitted': 3291,\n",
       " 'Tri': 14824,\n",
       " 'oro': 16522,\n",
       " 'ä½': 19526,\n",
       " 'dds': 33714,\n",
       " 'O': 46,\n",
       " 'ĠRM': 29820,\n",
       " 'Ġhurdle': 36633,\n",
       " 'pt': 457,\n",
       " 'Ġvon': 18042,\n",
       " 'ĠFab': 14236,\n",
       " 'lect': 801,\n",
       " 'ĠLuxem': 29017,\n",
       " 'ythm': 34853,\n",
       " 'ĠHits': 28626,\n",
       " 'ĠUs': 4021,\n",
       " 'Ġ##': 22492,\n",
       " 'Ġdean': 34798,\n",
       " 'ako': 25496,\n",
       " 'ĠRH': 35662,\n",
       " 'ĠRomance': 36555,\n",
       " 'ĠStout': 40275,\n",
       " 'illac': 40607,\n",
       " 'Ġsmarter': 23714,\n",
       " 'Ġfisheries': 41440,\n",
       " 'ĠMov': 44795,\n",
       " 'ĠLAT': 42355,\n",
       " 'Ġprotested': 27278,\n",
       " 'eneg': 46495,\n",
       " 'Bot': 20630,\n",
       " 'ĠNanto': 47614,\n",
       " 'ĠPhotos': 9434,\n",
       " 'Ġunpublished': 42686,\n",
       " 'ĠMage': 17323,\n",
       " 'Ġfuner': 49831,\n",
       " 'Ġsubmerged': 37930,\n",
       " 'Ġstag': 35251,\n",
       " 'ĠImam': 38386,\n",
       " 'ĠAsian': 7740,\n",
       " 'ĠCaption': 11260,\n",
       " 'ĠIgn': 16583,\n",
       " 'ĠDarren': 26203,\n",
       " 'ĠDumbledore': 27442,\n",
       " 'Ġadhesive': 43608,\n",
       " 'rup': 12618,\n",
       " 'ĠWing': 13405,\n",
       " 'Ġforcefully': 35701,\n",
       " 'ĠMacedonia': 36353,\n",
       " 'Ġelections': 7024,\n",
       " 'Ġdaring': 27939,\n",
       " 'phen': 31024,\n",
       " 'phalt': 41942,\n",
       " 'Ġitself': 2346,\n",
       " 'bage': 13866,\n",
       " 'OUN': 19385,\n",
       " '218': 28727,\n",
       " 'Ġsailor': 43272,\n",
       " 'Ġseparating': 27259,\n",
       " 'cru': 32838,\n",
       " 'texture': 41293,\n",
       " 'ĠMSM': 44401,\n",
       " 'ĠScotch': 46755,\n",
       " 'ments': 902,\n",
       " 'Ġpies': 47199,\n",
       " 'Ġdeserves': 14071,\n",
       " 'Ġhabitual': 46020,\n",
       " 'Lie': 47918,\n",
       " 'ĠExpect': 23600,\n",
       " 'ĠCrimean': 48062,\n",
       " 'Ġteaches': 17324,\n",
       " ...}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2 has a vocab of 50257 words, the provided vocab has 20500 words, and there are 3871 words in their intersection.\n"
     ]
    }
   ],
   "source": [
    "gpt_vocab = set(tokenizer.get_vocab().keys())\n",
    "\n",
    "print('GPT2 has a vocab of %d words, the provided vocab has %d words, and there are %d words in their intersection.' \n",
    "      %(len(gpt_vocab), len(vocab), len(set(vocab).intersection(gpt_vocab))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Increase the vocabulary\\n\\nnum_added_toks = tokenizer.add_tokens(vocab_with_symbol)\\n\\nprint('We have added', num_added_toks, 'tokens. New vocab size: ', len(set(tokenizer.get_vocab().keys())))\\n\\n# Notice: resize_token_embeddings expect to receive the full size of the new vocabulary, i.e., the length of the tokenizer.\\n\\nmodel.resize_token_embeddings(len(tokenizer))\\n\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Increase the vocabulary\n",
    "\n",
    "num_added_toks = tokenizer.add_tokens(vocab_with_symbol)\n",
    "\n",
    "print('We have added', num_added_toks, 'tokens. New vocab size: ', len(set(tokenizer.get_vocab().keys())))\n",
    "\n",
    "# Notice: resize_token_embeddings expect to receive the full size of the new vocabulary, i.e., the length of the tokenizer.\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dp', 'kg', 'Ġset', 'Ġprog', 'Ġname']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('dpkg set prog name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre process training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-9d82746b4bd06c73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:\\Users\\SP003DA2\\.cache\\huggingface\\datasets\\csv\\default-9d82746b4bd06c73\\0.0.0\\51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a95af0c88ad74cd9ae4016f53c89e715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c8c28a3ff94e359978b768b16ed18f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:\\Users\\SP003DA2\\.cache\\huggingface\\datasets\\csv\\default-9d82746b4bd06c73\\0.0.0\\51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5cf612734bb402694d542b71199d040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load names in a transformer format\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "dataset_dict = load_dataset('csv', data_files='names.csv')\n",
    "dataset = dataset_dict['train']\n",
    "dataset = dataset.train_test_split(test_size=0.05, shuffle=True, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Names'],\n",
       "        num_rows: 281906\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Names'],\n",
       "        num_rows: 14838\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Names': ' secs \\n'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"Names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf2d801c485e4b70a90cf925e9fb9c15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/282 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "832ebafc611e468e86f7739f0c9c6c45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize inputs\n",
    "tokenized_dataset = dataset.map(\n",
    "    tokenize_function, batched=True, remove_columns=[\"Names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [5412, 900, 3298, 13536, 220, 198],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[\"train\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' handle set global enables \\n'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_dataset[\"train\"][1]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ġattribute'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(11688)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# block_size = tokenizer.model_max_length\n",
    "block_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate inputs\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # Drop the small remainder\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d00e51a2416a4507a2c16c65b2d5cad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/282 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "718c193bf1514caa96ca9b42152289e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm_dataset = tokenized_dataset.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "#    num_proc=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 56369\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2957\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' test incremental no break \\n rl reap \\n check name \\n login manager skeleton get controllers \\n mcd null able variant equal \\n put h'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inputs changed:\n",
    "tokenizer.decode(lm_dataset[\"train\"][1][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize and fine-tune GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at distilgpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForCausalLM\n",
    "\n",
    "model = TFAutoModelForCausalLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import create_optimizer, AdamWeightDecay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamWeightDecay(lr=2e-5, weight_decay_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "data_collator = DefaultDataCollator(return_tensors=\"tf\")\n",
    "\n",
    "train_set = lm_dataset[\"train\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\"],\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "test_set = lm_dataset[\"test\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\"],\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3524/3524 [==============================] - 13831s 4s/step - loss: 4.3229 - val_loss: 3.9821\n",
      "Epoch 2/3\n",
      "3524/3524 [==============================] - 13900s 4s/step - loss: 3.9294 - val_loss: 3.7956\n",
      "Epoch 3/3\n",
      "3524/3524 [==============================] - 13650s 4s/step - loss: 3.7740 - val_loss: 3.6951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a112480808>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers.keras_callbacks import PushToHubCallback\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "push_to_hub_model_id = f\"{model_name}-finetuned-wikitext2\"\n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir=\"./clm_model_save/logs\")\n",
    "\n",
    "#push_to_hub_callback = PushToHubCallback(\n",
    "#    output_dir=\"./clm_model_save\",\n",
    "#    tokenizer=tokenizer,\n",
    "#    hub_model_id=push_to_hub_model_id,\n",
    "#)\n",
    "\n",
    "callbacks = [tensorboard_callback]#, push_to_hub_callback]\n",
    "\n",
    "model.fit(train_set, validation_data=test_set, epochs=3, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('FineTuned_GPT2_TF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-78-7146d0bffb59>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-78-7146d0bffb59>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    export OPENAI_GPT2_CHECKPOINT_PATH='FineTuned_GPT2_TF'\u001b[0m\n\u001b[1;37m                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "export OPENAI_GPT2_CHECKPOINT_PATH='FineTuned_GPT2_TF'\n",
    "\n",
    "transformers-cli convert --model_type gpt2 --tf_checkpoint $OPENAI_GPT2_CHECKPOINT_PATH --pytorch_dump_output $PYTORCH_DUMP_OUTPUT [--config OPENAI_GPT2_CONFIG] [--finetuning_task_name OPENAI_GPT2_FINETUNED_TASK]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load TF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"./FineTuned_GPT2_TF\", from_tf=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check here:\n",
    "# https://discuss.huggingface.co/t/prohibit-gpt-2-from-generating-some-words-on-a-condition/4823\n",
    "# https://discuss.huggingface.co/t/example-of-prefix-allowed-tokens-fn-while-text-generation/6635\n",
    "# https://huggingface.co/docs/transformers/v4.20.1/en/main_classes/text_generation#transformers.generation_utils.GenerationMixin.generate\n",
    "# and look for: prefix_allowed_tokens_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dp', 'kg', 'Ġset', 'Ġprog', 'Ġname']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('dpkg set prog name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated:  \n",
      " caml lwt unix get type \n",
      " caml lwt unix get\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate()  # do greedy decoding\n",
    "print(f\"Generated: {tokenizer.decode(outputs[0], skip_special_tokens=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(outputs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0: The dog \n",
      " gtk file chooser get type \n",
      " org gnome session manager call register client sync \n",
      " bamf match er get extension \n",
      " gf dbus screenshot proxy new\n",
      "Generated 1: The dog \n",
      " on read \n",
      " add to list \n",
      " snd mixer elem get volume \n",
      " caml oasis license find \n",
      " test initialize stress cb \n",
      " get value \n",
      "Generated 2: The dog \n",
      " read file \n",
      " gsm exported client skeleton finalize \n",
      " caml unit logger \n",
      " str ncpy \n",
      " cb get property \n",
      " uwf to ple\n"
     ]
    }
   ],
   "source": [
    "prompt = \"The dog\"\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"tf\")\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids=input_ids, max_length=40, temperature=0.7, num_return_sequences=3, do_sample=True\n",
    ")\n",
    "\n",
    "for i in range(3):  #  3 output sequences were generated\n",
    "    print(f\"Generated {i}: {tokenizer.decode(outputs[i], skip_special_tokens=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0: dpkg set prog name \n",
      " xfpm power management call get idle time \n",
      " caml\n",
      "Generated 1: dpkg set prog name \n",
      " xdp impl account skeleton handle set property \n",
      " cdw cd\n",
      "Generated 2: dpkg set prog name \n",
      " xdp impl account skeleton get version \n",
      " caml exp lib\n"
     ]
    }
   ],
   "source": [
    "prompt = 'dpkg set prog name'\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"tf\")\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids=input_ids, temperature=0.7, num_return_sequences=3, do_sample=True\n",
    ")\n",
    "\n",
    "for i in range(3):  #  3 output sequences were generated\n",
    "    print(f\"Generated {i}: {tokenizer.decode(outputs[i], skip_special_tokens=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0: dpkg set prog name \n",
      " games plugin page constructor \n",
      " ntfs fuse open dir \n",
      "Generated 1: dpkg set prog name \n",
      " do move \n",
      " caml oasis features make fun \n",
      "\n",
      "Generated 2: dpkg set prog name \n",
      " dl get \n",
      " lzma decode \n",
      " wix\n"
     ]
    }
   ],
   "source": [
    "prompt = 'dpkg set prog name'\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"tf\")\n",
    "\n",
    "force_words = 'functional'\n",
    "force_words_ids = tokenizer.encode(force_words, return_tensors=\"tf\")\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    force_words_ids=force_words_ids,\n",
    "    temperature=0.7, \n",
    "    num_return_sequences=3,\n",
    "    do_sample=True\n",
    ")\n",
    "\n",
    "for i in range(3):  #  3 output sequences were generated\n",
    "    print(f\"Generated {i}: {tokenizer.decode(outputs[i], skip_special_tokens=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outputs = model.generate(input_ids, do_sample=True, max_length=len(input_ids[0])+1, num_return_sequences=2, output_scores=True)\n",
    "#tokenizer.batch_decode(outputs[0], skip_special_tokens=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
